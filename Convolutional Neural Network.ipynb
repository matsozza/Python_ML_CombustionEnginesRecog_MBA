{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load necessary libraries ###\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug and test variables\n",
    "REDUCED_MODE = 1  # Do not process all the audio in the dataset (for faster execution during script development)\n",
    "REDUCED_MODE_AUDIONUM = 100 # Number of dataset audios per folder to process in the reduced-mode.\n",
    "\n",
    "# Audio processing variables\n",
    "AUDIO_SR = 44100 # Audio sampling in Hertz\n",
    "AUDIO_N_FFT = 2048 # Samples per FFT window\n",
    "AUDIO_WINSIZE = 1024\n",
    "AUDIO_HOP_LEN = 512\n",
    "AUDIO_N_MELS = 60\n",
    "AUDIOSEG_SIZE = 41 # windows per subAudio / segment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide an audio file into shorter parts.\n",
    "def audioSegmentation(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield int(start), int(start + window_size)\n",
    "        start += (window_size // 2)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define helper functions ###\n",
    "def extractSoundFeature(audiosPath,audiosSubPaths,audiosExtension=\"*.wav\", n_mels=AUDIO_N_MELS, n_windows=AUDIOSEG_SIZE, hopLength = AUDIO_HOP_LEN):\n",
    "    \n",
    "    subAudioSize = hopLength * (n_windows - 1)\n",
    "    features, classes = [], []\n",
    "    \n",
    "    # Map all audio samples paths inside the folder\n",
    "    allAudiosPath = glob.glob(os.path.join(audiosPath, audiosSubPath, audiosExtension));\n",
    "\n",
    "    # Iterate and extract features from each audio\n",
    "    idx = 0\n",
    "    for audioPath in allAudiosPath:\n",
    "        print('Processing sample: ', idx)\n",
    "        idx=idx+1;\n",
    "        \n",
    "        subAudioLogSpect = []\n",
    "        subAudioClass = []\n",
    "\n",
    "        # Extract '.wav' audio to an 1-D array\n",
    "        audioData, sr = librosa.load(audioPath, sr = AUDIO_SR)\n",
    "\n",
    "        # Extract audio classification from file name\n",
    "        audioClass = int(audioPath.split('/')[2].split('-')[1])\n",
    "\n",
    "        # Loop and extract all audio segments\n",
    "        for (start,end) in audioSegmentation(audioData, subAudioSize):\n",
    "            \n",
    "            if(len(audioData[start:end]) == subAudioSize):\n",
    "                signal = audioData[start:end]\n",
    "                melspec = librosa.feature.melspectrogram(y=signal,n_mels=n_mels)\n",
    "                print('melspec shape: ', np.shape(melspec))\n",
    "\n",
    "\n",
    "                logspec = librosa.amplitude_to_db(melspec)\n",
    "                print('logspec shape: ', np.shape(logspec))\n",
    "\n",
    "\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                print('logspec aft flatten shape: ', np.shape(logspec))\n",
    "\n",
    "\n",
    "                subAudioLogSpect.append(logspec)\n",
    "                print('subAudioLogSpect shape: ', np.shape(subAudioLogSpect))\n",
    "                subAudioClass.append(audioClass)\n",
    "            \n",
    "        subAudioLogSpect = np.asarray(subAudioLogSpect).reshape(len(subAudioLogSpect),n_mels,n_windows,1)\n",
    "        print('subAudioLogSpect shape final : ', np.shape(subAudioLogSpect))    \n",
    "\n",
    "        segment_features = np.concatenate( (subAudioLogSpect, np.zeros(np.shape(subAudioLogSpect))), axis=3 )\n",
    "        print('segment_features shape final: ', np.shape(segment_features)) # add an array of zeros in the last dimension\n",
    "\n",
    "            \n",
    "        for i in range(len(segment_features)): \n",
    "            segment_features[i, :, :, 1] = librosa.feature.delta(segment_features[i, :, :, 0]) #Calculate delta / derivative of axis 1\n",
    "        \n",
    "        if len(segment_features) > 0: # if not empty, concatenate in features / classes array\n",
    "            features.append(segment_features)\n",
    "            classes.append(subAudioClass)\n",
    "    \n",
    "        print('features shape final: ', np.shape(features))\n",
    "    \n",
    "    return features, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample:  0\n",
      "melspec shape:  (60, 41)\n",
      "logspec shape:  (60, 41)\n",
      "logspec aft flatten shape:  (1, 2460)\n",
      "subAudioLogSpect shape:  (1, 1, 2460)\n"
     ]
    }
   ],
   "source": [
    "# Pre-process and extract feature from the data\n",
    "audiosPath = 'UrbanSounds8K/audio/'\n",
    "save_dir = \"UrbanSounds8K/processed/\"\n",
    "folds = audiosSubPaths = np.array(['fold1','fold2','fold3','fold4', 'fold5','fold6','fold7','fold8', 'fold9','fold10'])\n",
    "for audiosSubPath in audiosSubPaths:\n",
    "    features, labels = extractSoundFeature(audiosPath,audiosSubPath)\n",
    "    #np.savez(\"{0}{1}\".format(save_dir, audiosSubPath), features=features, labels=labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define convolutional network architecture ###\n",
    "def get_network():\n",
    "    num_filters = [24,32,64,128] \n",
    "    pool_size = (2, 2) \n",
    "    kernel_size = (3, 3)  \n",
    "    input_shape = (60, 41, 2)\n",
    "    num_classes = 10\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(24, kernel_size,\n",
    "                padding=\"same\", input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "\n",
    "    model.add(keras.layers.GlobalMaxPooling2D())\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4), \n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and evaluate via 10-Folds cross-validation ###\n",
    "accuracies = []\n",
    "folds = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "load_dir = \"UrbanSounds8K/processed/\"\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001E5C8EAE180>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Starting a loop!\n",
      "-> Getting data from training folder  1\n",
      "-> Getting data from training folder  2\n",
      "-> Getting data from training folder  3\n",
      "-> Getting data from training folder  4\n",
      "-> Getting data from training folder  5\n",
      "-> Getting data from training folder  6\n",
      "-> Getting data from training folder  7\n",
      "-> Getting data from training folder  8\n",
      "-> Getting data from training folder  9\n",
      "-> Getting data from test folder  [0]\n",
      "--> Fitting model!\n",
      "Epoch 1/5\n",
      "2026/2026 [==============================] - 69s 34ms/step - loss: 1.1497 - accuracy: 0.6202\n",
      "Epoch 2/5\n",
      "2026/2026 [==============================] - 70s 35ms/step - loss: 0.6976 - accuracy: 0.7736\n",
      "Epoch 3/5\n",
      "2026/2026 [==============================] - 70s 34ms/step - loss: 0.5371 - accuracy: 0.8226\n",
      "Epoch 4/5\n",
      "2026/2026 [==============================] - 71s 35ms/step - loss: 0.4313 - accuracy: 0.8601\n",
      "Epoch 5/5\n",
      "2026/2026 [==============================] - 72s 35ms/step - loss: 0.3648 - accuracy: 0.8814\n",
      "test\n",
      "Average 10 Folds Accuracy: 0.5888917446323135\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "for train_index, test_index in kf.split(folds):\n",
    "    idx= idx+1\n",
    "    \n",
    "    print('--> Starting a loop!')\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "\n",
    "    # ---------------- STEP 1 ----------------\n",
    "    # Load training data from 9 of 10 folders \n",
    "    # Loop through all training folders and gather data in single feature array\n",
    "    for idxTrainFolder in train_index:\n",
    "        print('-> Getting data from TRAINING folder ', idxTrainFolder+1)\n",
    "        # Read pre-saved features or segments of an audio file (pre-processed)\n",
    "        train_data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[idxTrainFolder]), allow_pickle=True)\n",
    "\n",
    "        # Get the 'features' and 'labels' from current train folder\n",
    "        features = np.concatenate(train_data[\"features\"], axis=0) \n",
    "        labels = np.concatenate(train_data[\"labels\"], axis=0)\n",
    "\n",
    "        # Append all the 'features' and 'labels' train datasets \n",
    "        # in a single list containing all train folders data\n",
    "        x_train.append(features)\n",
    "        y_train.append(labels)\n",
    "\n",
    "    # Merge all separate feature datasets in a single one (as if it was a single 'big' folder)\n",
    "    x_train = np.concatenate(x_train, axis = 0).astype(np.float32)\n",
    "    y_train = np.concatenate(y_train, axis = 0).astype(np.float32)\n",
    "    \n",
    "    # ---------------- STEP 2 ----------------\n",
    "    # Load test data from 1 of 10 folders \n",
    "    # Load test data from the test folder\n",
    "    print('-> Getting data from TESTING folder ', test_index+1)\n",
    "    test_data = np.load(\"{0}/{1}.npz\".format(load_dir, folds[test_index][0]), allow_pickle=True)\n",
    "    x_test = test_data[\"features\"]\n",
    "    y_test = test_data[\"labels\"]\n",
    "\n",
    "    model = get_network()\n",
    "    \n",
    "    print('--> Fitting model!')\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs = 5, batch_size = 24, verbose = 1)\n",
    "    \n",
    "    # evaluate on test set/fold\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in zip(x_test, y_test):\n",
    "        # average predictions over segments of a sound clip\n",
    "        avg_p = np.argmax(np.mean(model.predict(x), axis = 0))\n",
    "        y_pred.append(avg_p) \n",
    "        # pick single label via np.unique for a sound clip\n",
    "        y_true.append(np.unique(y)[0]) \n",
    "    \n",
    "    accuracies.append(accuracy_score(y_true, y_pred))    \n",
    "\n",
    "    if idx == 1:\n",
    "        print('early break')\n",
    "        break;\n",
    "\n",
    "    print('Confusion matrix - loop: ', idx);\n",
    "    allConfusionMatrix(idx) = confusion_matrix(y_pred,y_true)\n",
    "    print(confusion_matrix)\n",
    "\n",
    "print(\"Average 10 Folds Accuracy: {0}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (2589643968.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [14]\u001b[1;36m\u001b[0m\n\u001b[1;33m    allConfusionMatrix(idx) = confusion_matrix(y_pred,y_true)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "allConfusionMatrix(idx) = confusion_matrix(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3c40342076cd490130f9df38b51275377a8f6bece07be498ddb041bf7f78465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
