{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load basic libraries ###\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from numpy import size\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import text, legend\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load audio libraries ###\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defs: Global Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug and test variables\n",
    "# Do not process all the sound in the dataset (for faster execution during script development)\n",
    "REDUCED_MODE = 0\n",
    "# Number of dataset sounds per folder to process in the reduced-mode.\n",
    "REDUCED_MODE_SOUNDNUM = 50\n",
    "\n",
    "# sound processing variables\n",
    "SOUND_SR = 44100  # sound sampling in Hertz\n",
    "SOUND_F_FFT = 2048  # Samples per FFT window\n",
    "SOUND_HOP_LEN = 512 # Hop Length\n",
    "SOUND_N_MELS = 25 # Number of mel frequencies to analyze\n",
    "\n",
    "SOUNDSEG_SIZE = 41  # windows per subsound / segment\n",
    "SOUNDSEG_OVERLAP = 0.4  # 40% overlapping factor for engine sounds\n",
    "\n",
    "SOUNDSEG_OVERSAMPLING = 4  # how many times to increase the engine category samples\n",
    "SOUNDSEG_CLASS2OVERSAMPLE = 5  # Oversample the engine class (num. 5)\n",
    "\n",
    "# Preprocessing\n",
    "PREPROC_SKIP = 1  # Skip preprocessing files and use previosuly saved '.npz'\n",
    "\n",
    "# CNN Processing\n",
    "CNN_EPOCHS = 20\n",
    "CNN_LEAKYRELU = 1\n",
    "CNN_BATCHSIZE = 32\n",
    "CNN_KERNELSIZE = (3,3)\n",
    "CNN_POOLSIZE = (2,2)\n",
    "\n",
    "# Paths and folders\n",
    "soundsPath = 'UrbanSounds8K/1_audioFiles/'\n",
    "soundsSubPaths = np.array(['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10'])\n",
    "preProcPath = \"UrbanSounds8K/2_featuresProcessed/\"\n",
    "trainingResultsPath = \"UrbanSounds8K/3_trainingResults/\"\n",
    "logPath = \"UrbanSounds8k/4_executionLog/\"\n",
    "\n",
    "confusionFile = \"confusion_matrix\"\n",
    "trainingFile = \"trainingResults\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defs: Data displaying and logging to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging both in console and file\n",
    "if not 'procLog' in vars():\n",
    "    sHand = logging.StreamHandler();\n",
    "    procLog = logging.getLogger('PreProc')\n",
    "    logging.basicConfig(level = logging.INFO,\n",
    "     filename = logPath + 'executionLog.log',\n",
    "      filemode = 'w', format = '%(asctime)s :: %(message)s',\n",
    "      datefmt='%d-%b-%y %H:%M:%S');\n",
    "    procLog.addHandler(sHand);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defs: Preprocessing and feature extraction from audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide an sound file into shorter and overlapped parts.\n",
    "def soundSegmentation(soundSignal, subsoundSize, overlapFactor=SOUNDSEG_OVERLAP):\n",
    "    start = 0\n",
    "    while start < len(soundSignal):\n",
    "        yield int(start), int(start + subsoundSize)\n",
    "        start += (subsoundSize // (1/(1-overlapFactor)))\n",
    "\n",
    "# Add white noise to signal respecting a maximum amplitude based on RMS energy of the original signal\n",
    "def soundAddGaussianNoise(soundSignal, sampleRate = SOUND_SR, maxAmplitude_percRMS = 0.1):\n",
    "    signalRMS = (np.average(soundSignal**2))**(1/2);\n",
    "    \n",
    "    randomFact1 = np.random.rand(1);\n",
    "    randomFact2 = np.random.rand(1);\n",
    "\n",
    "    factMax =  signalRMS * maxAmplitude_percRMS * (randomFact1 if randomFact1 > randomFact2 else randomFact2);\n",
    "    factMin =  signalRMS * maxAmplitude_percRMS * (randomFact1 if randomFact1 < randomFact2 else randomFact2);\n",
    "\n",
    "    transform = AddGaussianNoise(min_amplitude=factMin, max_amplitude=factMax,p=1);\n",
    "    augSoundSignal = transform(soundSignal,sample_rate=44100);\n",
    "\n",
    "    return augSoundSignal\n",
    "\n",
    "# Load sound with Librosa and make it faster or slower (time stretching)\n",
    "def soundLoadAndStretch(soundPath, sampleRate = SOUND_SR, maxStretch = 0.1):\n",
    "    randomFact = (np.random.rand(1) - 0.5) * maxStretch;\n",
    "    soundSignal, sr = librosa.load(soundPath, sr=SOUND_SR * (1+maxStretch));\n",
    "    return soundSignal;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from sound files, generating spectogram segments (images)\n",
    "def extractSoundFeature(soundsPath, soundsSubPath, n_mels=SOUND_N_MELS, n_windows=SOUNDSEG_SIZE, hopLength=SOUND_HOP_LEN,\n",
    "                        soundOversamplingFact=SOUNDSEG_OVERSAMPLING, soundOverClass=SOUNDSEG_CLASS2OVERSAMPLE):\n",
    "\n",
    "    subsoundSize = hopLength * (n_windows - 1)\n",
    "    features_AM, origClasses_A, segSounds_AA = [], [], []\n",
    "\n",
    "    # Map all sound samples paths inside the folder\n",
    "    allsoundsPath_A = glob.glob(os.path.join(\n",
    "        soundsPath, soundsSubPath, \"*.wav\"))\n",
    "\n",
    "    # Iterate and extract features from each sound\n",
    "    idxSound, idxSegment = 0, 0\n",
    "    for soundPath in allsoundsPath_A:\n",
    "        idxSound = idxSound+1\n",
    "        # Early stop for reduced mode\n",
    "        if REDUCED_MODE == 1 and idxSound == REDUCED_MODE_SOUNDNUM:\n",
    "            break\n",
    "\n",
    "        # Extract sound class by parsing file name\n",
    "        soundClass = int(soundPath.split('/')[2].split('-')[1])\n",
    "\n",
    "        # Loop more than once in the same sound (oversampling) if is engine class (5)\n",
    "        if soundClass == soundOverClass:\n",
    "            maxRepeatOverSampl = soundOversamplingFact  # Oversampling by repetition\n",
    "            overlapFactor = SOUNDSEG_OVERLAP  # Oversampling by overlapping\n",
    "        else:\n",
    "            maxRepeatOverSampl = 1\n",
    "            overlapFactor = 0\n",
    "\n",
    "        idxOverSampl = 0\n",
    "        for idxOverSampl in np.arange(maxRepeatOverSampl):\n",
    "\n",
    "            # Extract '.wav' sound to an 1-D array and apply stretching if required\n",
    "            if idxOverSampl > 0:\n",
    "                soungSignal_A = soundLoadAndStretch(\n",
    "                    soundPath, SOUND_SR, 0.1)  # stretch\n",
    "            else:\n",
    "                soungSignal_A = soundLoadAndStretch(\n",
    "                    soundPath, SOUND_SR, 0.0)  # don't stretch\n",
    "\n",
    "            # Create subsegments from sound file and extract the features\n",
    "            segSoundSignal_AA, segSoundSpect_AM, segSoundClass_A = [], [], []  # Init arrays\n",
    "            for (start, end) in soundSegmentation(soungSignal_A, subsoundSize, overlapFactor):\n",
    "                if (len(soungSignal_A[start:end]) == subsoundSize):\n",
    "                    idxSegment = idxSegment+1\n",
    "\n",
    "                    # Append sound class to segments class array\n",
    "                    segSoundClass_A.append(soundClass)\n",
    "\n",
    "                    # Extract segment from sound data - 1D Array\n",
    "                    segSoundSignal_A = soungSignal_A[start:end]\n",
    "                    segSoundSignal_AA.append(segSoundSignal_A)  # All segs. array\n",
    "\n",
    "                    # Apply data augmentation if repeated loop\n",
    "                    if idxOverSampl > 0:\n",
    "                        segSoundSignal_A = soundAddGaussianNoise(segSoundSignal_A, SOUND_SR, 0.1)\n",
    "\n",
    "                    # Transform to spectogram in decibels - 2D Matrix\n",
    "                    segsoundSpect_M = librosa.feature.mfcc(y=segSoundSignal_A, n_mfcc=n_mels)\n",
    "                    #segsoundSpect_M = librosa.feature.melspectrogram(y=segSoundSignal_A, n_mels=n_mels)\n",
    "                    #segsoundSpect_M = librosa.amplitude_to_db(segsoundSpect_M)\n",
    "\n",
    "                    # Reshape and append to preprocessed spectograms\n",
    "                    segsoundSpect_M = segsoundSpect_M.T.flatten()[:, np.newaxis].T\n",
    "                    segSoundSpect_AM.append(segsoundSpect_M)\n",
    "\n",
    "            segSoundSpect_AM = np.asarray(segSoundSpect_AM).reshape(len(segSoundSpect_AM), n_mels, n_windows, 1)\n",
    "\n",
    "            # If last sound not empty, stack together with others\n",
    "            if len(segSoundSpect_AM) > 0:\n",
    "                segSounds_AA.append(segSoundSignal_AA)\n",
    "                features_AM.append(segSoundSpect_AM)\n",
    "                origClasses_A.append(segSoundClass_A)\n",
    "    \n",
    "    procLog.log(msg = '-> Num of segments for '+ soundsSubPath +' -> ' + str(idxSegment) + \n",
    "                ' - out of - ' + str(idxSound) + ' sounds.', level=20)\n",
    "\n",
    "    # Stack all data 'per segment' and not 'per sound'\n",
    "    segSounds_AA = np.concatenate(segSounds_AA, axis=0)\n",
    "    features_AM = np.concatenate(features_AM, axis=0)\n",
    "    origClasses_A = np.concatenate(origClasses_A, axis=0)\n",
    "\n",
    "    # Convert UrbanSounds8K class to binary 'is/isn't engine'\n",
    "    engineClasses_A = np.array(\n",
    "        list(map(lambda x: 1 if x == 5 else 0, origClasses_A)))\n",
    "\n",
    "    return segSounds_AA, features_AM, engineClasses_A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defs: CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convolutional network architecture ###\n",
    "def CNN_modelDefinition(useLeakyRelu=0):\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    pool_size = CNN_POOLSIZE\n",
    "    kernel_size = CNN_KERNELSIZE\n",
    "    input_shape = (SOUND_N_MELS, SOUNDSEG_SIZE, 1)\n",
    "    num_classes = 2  \n",
    "\n",
    "    # ---------- Convolutional + Pooling Layer 1 ---------- #\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(80, kernel_size, padding=\"same\",\n",
    "              input_shape=input_shape, dilation_rate=1))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    if useLeakyRelu == 0:\n",
    "        model.add(keras.layers.Activation(\"relu\"))\n",
    "    else:\n",
    "        model.add(keras.layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    # ---------- Convolutional + Pooling Layer 2 ---------- #\n",
    "    model.add(keras.layers.Conv2D(80, kernel_size,\n",
    "              padding=\"same\", dilation_rate=2))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    if useLeakyRelu == 0:\n",
    "        model.add(keras.layers.Activation(\"relu\"))\n",
    "    else:\n",
    "        model.add(keras.layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    # ---------- Pooling Layer Layer ---------- #\n",
    "    model.add(keras.layers.GlobalMaxPooling2D())\n",
    "\n",
    "    # ---------- Flat Layers ---------- #\n",
    "    model.add(keras.layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4), loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proc: Sound Processing and Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process and extract feature from the data\n",
    "if PREPROC_SKIP == 0:\n",
    "    fig, axes = plt.subplots(2, 5, dpi=120);\n",
    "    axes = axes.ravel();\n",
    "    fig.set_figheight(10*0.5); fig.set_figwidth(25*0.5); fig.tight_layout(pad=4.5);\n",
    "\n",
    "    # Loop through all sound folders\n",
    "    idxFold = 0\n",
    "    for soundSubPath in soundsSubPaths:\n",
    "        # Extract files from folder and save externally for reuse\n",
    "        segSounds_AA, features_AM, classes_A = extractSoundFeature(soundsPath, soundSubPath)\n",
    "        np.savez(\"{0}{1}\".format(preProcPath, soundSubPath), segSounds = segSounds_AA, features=features_AM, classes=classes_A);\n",
    "        # Plot histogram of data balancing per folder\n",
    "        axes[idxFold].set_title('Folder ' + str(idxFold+1) + ' balancing')\n",
    "        tmpData = np.asarray(classes_A)\n",
    "        tmpData = [np.count_nonzero(tmpData == 0),\n",
    "                   np.count_nonzero(tmpData == 1)]\n",
    "        axes[idxFold].bar(['Not Eng.', 'Eng.'], tmpData,\n",
    "                          align='edge', width=-0.4, label=\"Train\")\n",
    "        idxFold += 1\n",
    "    fig.savefig(fname = logPath + '1_foldersProcessing.jpg' );\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proc:  CNN Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and evaluate via 10-soundsSubPaths cross-validation ###\n",
    "kf = KFold(n_splits=10);\n",
    "\n",
    "# List containing all confusion matrix for all K-Fold Train-Test.\n",
    "# Array containing the results of the training for each train/test set.\n",
    "allConfusionMatrix_AM, allFitResults_A, allCNNModels_A = [], [], [];\n",
    "bestConfusionMatrix_AM, bestCNNModels_A = [], []\n",
    "\n",
    "# Loop to train-test in all folder combinations.\n",
    "idx = 0\n",
    "for train_index, test_index in kf.split(soundsSubPaths):\n",
    "    idx = idx+1;\n",
    "    procLog.info('----------> PROC: Starting a loop! - Folder ' + str(idx)+ ' <----------');\n",
    "    x_train, y_train = [], [];\n",
    "\n",
    "    # ---------------- STEP 1 ----------------\n",
    "    # Load training data from 9 out of 10 folders\n",
    "    # Loop through all training folders and gather data in single feature array\n",
    "    for idxTrainFolder in train_index:\n",
    "        procLog.info('-> Getting data from TRAINING folder ' +  str(idxTrainFolder+1));\n",
    "        # Read pre-saved features or segments of an sound file (pre-processed)\n",
    "        train_data = np.load(\"{0}/{1}.npz\".format(preProcPath, soundsSubPaths[idxTrainFolder]), allow_pickle=True);\n",
    "\n",
    "        # Append all the 'features/classes' train datasets in a single list (all folders)\n",
    "        x_train.append(train_data[\"features\"]);\n",
    "        y_train.append(train_data[\"classes\"]);\n",
    "\n",
    "    # Stack all the folders in a single X/Y dataset\n",
    "    x_train = np.concatenate(x_train, axis=0).astype(np.float32);\n",
    "    y_train = np.concatenate(y_train, axis=0).astype(np.float32);\n",
    "    procLog.info('-> TRAIN dataset size: ' + str(len(x_train)));\n",
    "\n",
    "    # ---------------- STEP 2 ----------------\n",
    "    # Load test data from 1 out of 10 folders\n",
    "    procLog.info('-> Getting data from TESTING folder ' + str(test_index+1));\n",
    "    test_data = np.load(\"{0}/{1}.npz\".format(preProcPath, soundsSubPaths[test_index][0]), allow_pickle=True);\n",
    "    x_test, y_test = test_data[\"features\"], test_data[\"classes\"];\n",
    "    procLog.info('-> TEST dataset size: ' + str(len(x_test)));\n",
    "\n",
    "    # Load and fit the CNN Model + Callbacks\n",
    "    procLog.info('-> Fitting model!');\n",
    "    CNN_model = CNN_modelDefinition(useLeakyRelu=CNN_LEAKYRELU);\n",
    "\n",
    "    earlyStopCB = keras.callbacks.EarlyStopping(monitor='loss', patience=3,min_delta=0, verbose=1, restore_best_weights= True);\n",
    "    \n",
    "    mdlCheckPointPath = \"{0}{1}{2}\".format(trainingResultsPath, 'CNN_bestWeights_', idx);\n",
    "    mdlCheckpointCB = keras.callbacks.ModelCheckpoint(filepath=mdlCheckPointPath, monitor='val_accuracy', mode='max', save_best_only=True);\n",
    "    \n",
    "    allFitResults_A.append(CNN_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=CNN_EPOCHS, batch_size=CNN_BATCHSIZE, verbose=0, callbacks=[earlyStopCB,mdlCheckpointCB]));\n",
    "    allCNNModels_A.append(CNN_model); # Append complete CNN model for testing afterwards\n",
    "\n",
    "    # Save model data to log\n",
    "    procLog.info('-> Accuracy:' + str(allFitResults_A[-1].history[\"accuracy\"][-1]));\n",
    "    procLog.info('-> Val. Accuracy:' + str(allFitResults_A[-1].history[\"val_accuracy\"][-1]));\n",
    "    procLog.info('-> Loss:' + str(allFitResults_A[-1].history[\"loss\"][-1]));\n",
    "    procLog.info('-> Val. Loss:' + str(allFitResults_A[-1].history[\"val_loss\"][-1]));\n",
    "\n",
    "    # Predict results from test data\n",
    "    y_test_pred = CNN_model.predict(x_test);  # Categorical results\n",
    "    y_test_pred = np.asarray(tf.argmax(y_test_pred, axis=1));  # OHE to Category\n",
    "\n",
    "    # Calculate and append the confusion matrix of this K-Fold run to a matrix list\n",
    "    allConfusionMatrix_AM.append(confusion_matrix(y_test, y_test_pred, normalize='true'));\n",
    "    \n",
    "    # ---------------- STEP 3 ----------------\n",
    "    # Get the best model (best epoch) & append it\n",
    "    bestModel = CNN_modelDefinition(useLeakyRelu=CNN_LEAKYRELU);\n",
    "    bestModel.load_weights(mdlCheckPointPath);\n",
    "    bestCNNModels_A.append(bestModel);\n",
    "\n",
    "    # Predict results from test data in best model\n",
    "    y_test_pred_best = bestModel.predict(x_test);  # Categorical results\n",
    "    y_test_pred_best = np.asarray(tf.argmax(y_test_pred_best, axis=1));  # OHE to Category\n",
    "\n",
    "    # Calculate best confusion matrix\n",
    "    bestConfusionMatrix_AM.append(confusion_matrix(y_test, y_test_pred_best, normalize='true'));\n",
    "\n",
    "    # Early break for reduced mode\n",
    "    if REDUCED_MODE == 1 and idx == 4:\n",
    "        break;\n",
    "\n",
    "# Save the resulting confusion matrices and training data to file\n",
    "np.savez(\"{0}{1}\".format(trainingResultsPath, confusionFile), allConfusionMatrix_AM=allConfusionMatrix_AM, bestConfusionMatrix_AM=bestConfusionMatrix_AM);\n",
    "np.savez(\"{0}{1}\".format(trainingResultsPath, trainingFile), allFitResults_A=allFitResults_A, allCNNModels_A = allCNNModels_A, bestCNNModels_A=bestCNNModels_A);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class identifiers according to UrbanSounds 8k :\n",
    "\n",
    "0 = air_conditioner\n",
    "1 = car_horn\n",
    "2 = children_playing\n",
    "3 = dog_bark\n",
    "4 = drilling\n",
    "5 = engine_idling\n",
    "6 = gun_shot\n",
    "7 = jackhammer\n",
    "8 = siren\n",
    "9 = street_music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze: Plot all the final confusion matrices + final average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from pre-saved file\n",
    "allConfusionMatrix_AM = np.load(\n",
    "    \"{0}/{1}.npz\".format(trainingResultsPath, confusionFile), allow_pickle=True)[\"allConfusionMatrix_AM\"]\n",
    "\n",
    "# Plot all confusion matrix\n",
    "fig, axes = plt.subplots(2, 5, dpi=120)\n",
    "fig.set_figheight(10*.5); fig.set_figwidth(25*.5); fig.tight_layout(pad=4.5)\n",
    "\n",
    "idxRow, idxCol = 0, 0\n",
    "for cm in allConfusionMatrix_AM:\n",
    "    axes[idxRow][idxCol].set_title('Fold. ' + str(5*idxRow+idxCol+1) + ' test')\n",
    "    if idxCol == 0:\n",
    "        cmDisplay = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Eng.', 'Engine'])\n",
    "    else:\n",
    "        cmDisplay = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    cmPlt = cmDisplay.plot(ax=axes[idxRow][idxCol], cmap='cividis', xticks_rotation='vertical');\n",
    "\n",
    "    idxCol += 1\n",
    "    if idxCol == 5:\n",
    "        idxCol, idxRow = 0, 1;\n",
    "    fig.savefig(fname = logPath + '2_allConfusionMatrix.jpg' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average results\n",
    "confusionMatrixAvg_M = np.zeros([2,2]);\n",
    "for cm in allConfusionMatrix_AM:\n",
    "    confusionMatrixAvg_M += cm;\n",
    "confusionMatrixAvg_M *=0.1;\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(dpi=120)\n",
    "fig.set_figheight(2); fig.set_figwidth(2); fig.tight_layout(pad=0.5);\n",
    "axes.set_title('Avg. Matrix')\n",
    "cmDisplay = ConfusionMatrixDisplay(confusion_matrix=confusionMatrixAvg_M, display_labels=['Not Eng.', 'Engine'])\n",
    "cmDisplay.plot(ax=axes,  cmap='inferno', xticks_rotation='vertical')\n",
    "\n",
    "fig.savefig(fname = logPath + '3_avgConfusionMatrix.jpg' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze: Plot the best confusion matrices + best average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from pre-saved file\n",
    "bestConfusionMatrix_AM = np.load(\n",
    "    \"{0}/{1}.npz\".format(trainingResultsPath, confusionFile), allow_pickle=True)[\"bestConfusionMatrix_AM\"]\n",
    "\n",
    "# Plot all confusion matrix\n",
    "fig, axes = plt.subplots(2, 5, dpi=120)\n",
    "fig.set_figheight(10*.5); fig.set_figwidth(25*.5); fig.tight_layout(pad=4.5)\n",
    "\n",
    "idxRow, idxCol = 0, 0\n",
    "for cm in bestConfusionMatrix_AM:\n",
    "    axes[idxRow][idxCol].set_title('Best Fold. ' + str(5*idxRow+idxCol+1) + '')\n",
    "    if idxCol == 0:\n",
    "        cmDisplay = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Eng.', 'Engine'])\n",
    "    else:\n",
    "        cmDisplay = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    cmPlt = cmDisplay.plot(ax=axes[idxRow][idxCol], cmap='cividis', xticks_rotation='vertical');\n",
    "\n",
    "    idxCol += 1\n",
    "    if idxCol == 5:\n",
    "        idxCol, idxRow = 0, 1;\n",
    "    fig.savefig(fname = logPath + '2b_bestConfusionMatrix.jpg' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average results\n",
    "bestMatrixAvg_M = np.zeros([2,2]);\n",
    "for cm in bestConfusionMatrix_AM:\n",
    "    bestMatrixAvg_M += cm;\n",
    "bestMatrixAvg_M *=0.1;\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(dpi=120)\n",
    "fig.set_figheight(2); fig.set_figwidth(2); fig.tight_layout(pad=0.5);\n",
    "axes.set_title('Best Avg. Matr.')\n",
    "cmDisplay = ConfusionMatrixDisplay(confusion_matrix=bestMatrixAvg_M, display_labels=['Not Eng.', 'Engine'])\n",
    "cmDisplay.plot(ax=axes,  cmap='inferno', xticks_rotation='vertical')\n",
    "fig.savefig(fname = logPath + '3b_avgConfusionMatrix.jpg' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze: Plot training and testing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, axes = plt.subplots(2,5,dpi=120)\n",
    "fig.set_figheight(10*.5); fig.set_figwidth(25*.5); fig.tight_layout(pad=4.5)\n",
    "\n",
    "idxRow, idxCol = 0, 0\n",
    "for resPlot in allFitResults_A:\n",
    "    axes[idxRow][idxCol].set_title('Folder ' + str(5*idxRow+idxCol+1) + ' as test')\n",
    "    axes[idxRow][idxCol].plot(resPlot.history['accuracy']); \n",
    "    axes[idxRow][idxCol].plot(resPlot.history['val_accuracy']);\n",
    "    axes[idxRow][idxCol].set(ylabel = 'Accuracy', xlabel= 'Epochs');\n",
    "    idxCol += 1\n",
    "    if idxCol == 5:\n",
    "        idxCol, idxRow = 0, 1;\n",
    "fig.legend(['Train' , 'Test'], loc=5, bbox_to_anchor=(1, 0.505), fontsize = 'medium');\n",
    "fig.savefig(fname = logPath + '4_allTrainTestStats.jpg' );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average results\n",
    "avgAcc = np.zeros(np.shape(allFitResults_A[0].history['accuracy']))\n",
    "avgValAcc = np.zeros(np.shape(allFitResults_A[0].history['val_accuracy']))\n",
    "for resPlot in allFitResults_A:\n",
    "    avgAcc += resPlot.history['accuracy'];\n",
    "    avgValAcc += resPlot.history['val_accuracy'];\n",
    "avgAcc*=0.1; avgValAcc*=0.1;\n",
    "\n",
    "#Plot\n",
    "fig, axes = plt.subplots(dpi=120)\n",
    "fig.set_figheight(2); fig.set_figwidth(3.5); fig.tight_layout(pad=0.5);\n",
    "\n",
    "axes.set_title('Avg. of 10 sets')\n",
    "plt.plot(avgAcc);\n",
    "plt.plot(avgValAcc);\n",
    "fig.legend(['Train' , 'Test'], loc=1, bbox_to_anchor=(1.075, 1.1), fontsize = 'x-small');\n",
    "fig.savefig(fname = logPath + '5_avgTrainTestStats.jpg' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc: Sound segment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a non-engine sound\n",
    "for idx in np.arange( len(train_data[\"classes\"])  ):\n",
    "    if train_data[\"classes\"][idx] == 0:\n",
    "        print('Found!');\n",
    "        break;\n",
    "\n",
    "Audio(train_data[\"segSounds\"][idx], rate=SOUND_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find an engine sound\n",
    "for idx in np.arange( len(train_data[\"classes\"])  ):\n",
    "    if train_data[\"classes\"][idx] == 1:\n",
    "        print('Found!');\n",
    "        break;\n",
    "\n",
    "Audio(train_data[\"segSounds\"][idx], rate=SOUND_SR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot categories distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(2, 5)\n",
    "a = a.ravel()\n",
    "\n",
    "f.set_figheight(10*0.5)\n",
    "f.set_figwidth(25*0.5)\n",
    "f.tight_layout(pad=4.5)\n",
    "\n",
    "a[0].set_title('Train/Test balancing')\n",
    "\n",
    "# Histogram of data per class in train dataset\n",
    "tmpData = np.asarray(train_data[\"classes\"])\n",
    "tmpData = [np.count_nonzero(tmpData == 0), np.count_nonzero(tmpData == 1)]\n",
    "a[0].bar(['Not Eng.', 'Eng.'], tmpData,\n",
    "         align='edge', width=-0.4, label=\"Train\")\n",
    "\n",
    "# Histogram of data per class in test dataset\n",
    "tmpData = np.asarray(test_data[\"classes\"])\n",
    "tmpData = [np.count_nonzero(tmpData == 0), np.count_nonzero(tmpData == 1)]\n",
    "a[0].bar(['Not Eng.', 'Eng.'], tmpData, align='edge', width=0.4, label=\"Test\")\n",
    "\n",
    "f.legend(fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procLog.info(allFitResults_A[-1].history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3c40342076cd490130f9df38b51275377a8f6bece07be498ddb041bf7f78465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
